{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ru9xg6QIaceV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import pickle\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "STeZ46Y4bKfl"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>menopause</th>\n",
              "      <th>tumor-size</th>\n",
              "      <th>inv-nodes</th>\n",
              "      <th>node-caps</th>\n",
              "      <th>deg-malig</th>\n",
              "      <th>breast</th>\n",
              "      <th>breast-quad</th>\n",
              "      <th>irradiat</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>281</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>282</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>283</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>285</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>286 rows Ã— 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     age  menopause  tumor-size  inv-nodes  node-caps  deg-malig  breast  \\\n",
              "0      2          2           2          0          2          3       1   \n",
              "1      3          0           2          0          1          1       1   \n",
              "2      3          0           6          0          1          2       0   \n",
              "3      2          2           6          0          2          3       1   \n",
              "4      2          2           5          4          2          2       0   \n",
              "..   ...        ...         ...        ...        ...        ...     ...   \n",
              "281    3          0           5          5          2          2       0   \n",
              "282    3          2           4          4          2          2       0   \n",
              "283    1          2           5          5          2          2       1   \n",
              "284    3          2           2          0          1          2       1   \n",
              "285    3          0           7          0          1          3       0   \n",
              "\n",
              "     breast-quad  irradiat  Class  \n",
              "0              3         0      1  \n",
              "1              1         0      0  \n",
              "2              2         0      1  \n",
              "3              2         1      0  \n",
              "4              5         0      1  \n",
              "..           ...       ...    ...  \n",
              "281            2         0      0  \n",
              "282            2         1      0  \n",
              "283            5         0      0  \n",
              "284            2         0      0  \n",
              "285            5         0      0  \n",
              "\n",
              "[286 rows x 10 columns]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_csv('breast-cancer.csv');\n",
        "\n",
        "data_numeric = data.copy()\n",
        "\n",
        "label_encoders = {}\n",
        "categorical_columns = ['age', 'menopause', 'tumor-size', 'inv-nodes', 'node-caps', 'breast', 'breast-quad', 'irradiat', 'Class']\n",
        "\n",
        "for column in categorical_columns:\n",
        "    le = LabelEncoder()\n",
        "    data_numeric[column] = le.fit_transform(data_numeric[column])\n",
        "    label_encoders[column] = le\n",
        "\n",
        "\n",
        "data_numeric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = data_numeric.drop('Class', axis=1)\n",
        "y = data_numeric['Class']\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVW22XucaswH",
        "outputId": "2c08bca3-ed7c-4d92-c4a9-8030b70af513"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/raul/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"â–¸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"â–¾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MLPClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.neural_network.MLPClassifier.html\">?<span>Documentation for MLPClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MLPClassifier()</pre></div> </div></div></div></div>"
            ],
            "text/plain": [
              "MLPClassifier()"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "modelo = MLPClassifier()\n",
        "modelo.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QRptikHHepQ",
        "outputId": "f0106c94-1301-44e9-be60-e108bf82bebb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1.16443845\n",
            "Iteration 2, loss = 1.02525448\n",
            "Iteration 3, loss = 0.90474066\n",
            "Iteration 4, loss = 0.80361359\n",
            "Iteration 5, loss = 0.72039258\n",
            "Iteration 6, loss = 0.66461221\n",
            "Iteration 7, loss = 0.62830237\n",
            "Iteration 8, loss = 0.60653773\n",
            "Iteration 9, loss = 0.59737023\n",
            "Iteration 10, loss = 0.60047894\n",
            "Iteration 11, loss = 0.60287480\n",
            "Iteration 12, loss = 0.60640538\n",
            "Iteration 13, loss = 0.60902526\n",
            "Iteration 14, loss = 0.61061627\n",
            "Iteration 15, loss = 0.60860081\n",
            "Iteration 16, loss = 0.60415321\n",
            "Iteration 17, loss = 0.59793516\n",
            "Iteration 18, loss = 0.59146164\n",
            "Iteration 19, loss = 0.58629983\n",
            "Iteration 20, loss = 0.58152802\n",
            "Iteration 21, loss = 0.57828905\n",
            "Iteration 22, loss = 0.57585625\n",
            "Iteration 23, loss = 0.57425357\n",
            "Iteration 24, loss = 0.57309046\n",
            "Iteration 25, loss = 0.57200206\n",
            "Iteration 26, loss = 0.57152145\n",
            "Iteration 27, loss = 0.57108633\n",
            "Iteration 28, loss = 0.57135754\n",
            "Iteration 29, loss = 0.57137039\n",
            "Iteration 30, loss = 0.57048569\n",
            "Iteration 31, loss = 0.56844558\n",
            "Iteration 32, loss = 0.56607471\n",
            "Iteration 33, loss = 0.56356269\n",
            "Iteration 34, loss = 0.56265601\n",
            "Iteration 35, loss = 0.56291866\n",
            "Iteration 36, loss = 0.56325196\n",
            "Iteration 37, loss = 0.56311782\n",
            "Iteration 38, loss = 0.56180393\n",
            "Iteration 39, loss = 0.55966911\n",
            "Iteration 40, loss = 0.55852995\n",
            "Iteration 41, loss = 0.55810571\n",
            "Iteration 42, loss = 0.55806563\n",
            "Iteration 43, loss = 0.55756138\n",
            "Iteration 44, loss = 0.55712106\n",
            "Iteration 45, loss = 0.55640156\n",
            "Iteration 46, loss = 0.55536219\n",
            "Iteration 47, loss = 0.55450321\n",
            "Iteration 48, loss = 0.55332651\n",
            "Iteration 49, loss = 0.55250365\n",
            "Iteration 50, loss = 0.55167051\n",
            "Iteration 51, loss = 0.55095572\n",
            "Iteration 52, loss = 0.55030400\n",
            "Iteration 53, loss = 0.54972953\n",
            "Iteration 54, loss = 0.54901037\n",
            "Iteration 55, loss = 0.54813072\n",
            "Iteration 56, loss = 0.54745535\n",
            "Iteration 57, loss = 0.54650601\n",
            "Iteration 58, loss = 0.54585763\n",
            "Iteration 59, loss = 0.54509117\n",
            "Iteration 60, loss = 0.54454136\n",
            "Iteration 61, loss = 0.54430592\n",
            "Iteration 62, loss = 0.54450332\n",
            "Iteration 63, loss = 0.54450921\n",
            "Iteration 64, loss = 0.54437461\n",
            "Iteration 65, loss = 0.54466645\n",
            "Iteration 66, loss = 0.54426556\n",
            "Iteration 67, loss = 0.54286442\n",
            "Iteration 68, loss = 0.54200517\n",
            "Iteration 69, loss = 0.54057473\n",
            "Iteration 70, loss = 0.53913244\n",
            "Iteration 71, loss = 0.53824682\n",
            "Iteration 72, loss = 0.53875112\n",
            "Iteration 73, loss = 0.53854512\n",
            "Iteration 74, loss = 0.53811157\n",
            "Iteration 75, loss = 0.53749269\n",
            "Iteration 76, loss = 0.53680160\n",
            "Iteration 77, loss = 0.53616995\n",
            "Iteration 78, loss = 0.53565201\n",
            "Iteration 79, loss = 0.53508948\n",
            "Iteration 80, loss = 0.53437985\n",
            "Iteration 81, loss = 0.53396041\n",
            "Iteration 82, loss = 0.53343823\n",
            "Iteration 83, loss = 0.53351340\n",
            "Iteration 84, loss = 0.53334403\n",
            "Iteration 85, loss = 0.53306266\n",
            "Iteration 86, loss = 0.53236120\n",
            "Iteration 87, loss = 0.53181390\n",
            "Iteration 88, loss = 0.53145052\n",
            "Iteration 89, loss = 0.53103890\n",
            "Iteration 90, loss = 0.53049830\n",
            "Iteration 91, loss = 0.53007283\n",
            "Iteration 92, loss = 0.52970337\n",
            "Iteration 93, loss = 0.52934690\n",
            "Iteration 94, loss = 0.52963161\n",
            "Iteration 95, loss = 0.52893137\n",
            "Iteration 96, loss = 0.52824898\n",
            "Iteration 97, loss = 0.52771041\n",
            "Iteration 98, loss = 0.52740964\n",
            "Iteration 99, loss = 0.52736202\n",
            "Iteration 100, loss = 0.52761383\n",
            "Iteration 101, loss = 0.52678744\n",
            "Iteration 102, loss = 0.52621690\n",
            "Iteration 103, loss = 0.52532228\n",
            "Iteration 104, loss = 0.52529530\n",
            "Iteration 105, loss = 0.52531034\n",
            "Iteration 106, loss = 0.52478118\n",
            "Iteration 107, loss = 0.52420974\n",
            "Iteration 108, loss = 0.52383024\n",
            "Iteration 109, loss = 0.52319919\n",
            "Iteration 110, loss = 0.52451797\n",
            "Iteration 111, loss = 0.52494420\n",
            "Iteration 112, loss = 0.52450604\n",
            "Iteration 113, loss = 0.52315314\n",
            "Iteration 114, loss = 0.52171306\n",
            "Iteration 115, loss = 0.52169005\n",
            "Iteration 116, loss = 0.52179744\n",
            "Iteration 117, loss = 0.52160781\n",
            "Iteration 118, loss = 0.52095964\n",
            "Iteration 119, loss = 0.52041719\n",
            "Iteration 120, loss = 0.51980585\n",
            "Iteration 121, loss = 0.52022122\n",
            "Iteration 122, loss = 0.51959759\n",
            "Iteration 123, loss = 0.51922717\n",
            "Iteration 124, loss = 0.51861501\n",
            "Iteration 125, loss = 0.51835542\n",
            "Iteration 126, loss = 0.51805473\n",
            "Iteration 127, loss = 0.51789786\n",
            "Iteration 128, loss = 0.51751142\n",
            "Iteration 129, loss = 0.51728518\n",
            "Iteration 130, loss = 0.51676644\n",
            "Iteration 131, loss = 0.51637041\n",
            "Iteration 132, loss = 0.51640906\n",
            "Iteration 133, loss = 0.51822024\n",
            "Iteration 134, loss = 0.51998605\n",
            "Iteration 135, loss = 0.51936879\n",
            "Iteration 136, loss = 0.51735271\n",
            "Iteration 137, loss = 0.51601746\n",
            "Iteration 138, loss = 0.51445356\n",
            "Iteration 139, loss = 0.51342486\n",
            "Iteration 140, loss = 0.51315823\n",
            "Iteration 141, loss = 0.51320255\n",
            "Iteration 142, loss = 0.51379562\n",
            "Iteration 143, loss = 0.51400556\n",
            "Iteration 144, loss = 0.51340216\n",
            "Iteration 145, loss = 0.51212198\n",
            "Iteration 146, loss = 0.51133392\n",
            "Iteration 147, loss = 0.51055727\n",
            "Iteration 148, loss = 0.51149224\n",
            "Iteration 149, loss = 0.51081805\n",
            "Iteration 150, loss = 0.51028393\n",
            "Iteration 151, loss = 0.50962849\n",
            "Iteration 152, loss = 0.50940595\n",
            "Iteration 153, loss = 0.51015843\n",
            "Iteration 154, loss = 0.51213350\n",
            "Iteration 155, loss = 0.51405106\n",
            "Iteration 156, loss = 0.51473328\n",
            "Iteration 157, loss = 0.51214067\n",
            "Iteration 158, loss = 0.50975860\n",
            "Iteration 159, loss = 0.50721667\n",
            "Iteration 160, loss = 0.50661207\n",
            "Iteration 161, loss = 0.50625756\n",
            "Iteration 162, loss = 0.50633077\n",
            "Iteration 163, loss = 0.50636044\n",
            "Iteration 164, loss = 0.50655010\n",
            "Iteration 165, loss = 0.50644218\n",
            "Iteration 166, loss = 0.50605238\n",
            "Iteration 167, loss = 0.50595095\n",
            "Iteration 168, loss = 0.50549343\n",
            "Iteration 169, loss = 0.50465541\n",
            "Iteration 170, loss = 0.50397866\n",
            "Iteration 171, loss = 0.50326511\n",
            "Iteration 172, loss = 0.50341399\n",
            "Iteration 173, loss = 0.50395472\n",
            "Iteration 174, loss = 0.50417826\n",
            "Iteration 175, loss = 0.50412096\n",
            "Iteration 176, loss = 0.50307418\n",
            "Iteration 177, loss = 0.50248416\n",
            "Iteration 178, loss = 0.50129187\n",
            "Iteration 179, loss = 0.50132375\n",
            "Iteration 180, loss = 0.49978972\n",
            "Iteration 181, loss = 0.50033963\n",
            "Iteration 182, loss = 0.50131911\n",
            "Iteration 183, loss = 0.50160401\n",
            "Iteration 184, loss = 0.50163070\n",
            "Iteration 185, loss = 0.50196908\n",
            "Iteration 186, loss = 0.50007103\n",
            "Iteration 187, loss = 0.49813932\n",
            "Iteration 188, loss = 0.49701286\n",
            "Iteration 189, loss = 0.49746560\n",
            "Iteration 190, loss = 0.49838647\n",
            "Iteration 191, loss = 0.49991005\n",
            "Iteration 192, loss = 0.49956931\n",
            "Iteration 193, loss = 0.49779556\n",
            "Iteration 194, loss = 0.49623294\n",
            "Iteration 195, loss = 0.49484731\n",
            "Iteration 196, loss = 0.49392069\n",
            "Iteration 197, loss = 0.49381241\n",
            "Iteration 198, loss = 0.49365761\n",
            "Iteration 199, loss = 0.49361676\n",
            "Iteration 200, loss = 0.49369045\n",
            "Iteration 201, loss = 0.49330639\n",
            "Iteration 202, loss = 0.49259581\n",
            "Iteration 203, loss = 0.49222426\n",
            "Iteration 204, loss = 0.49150707\n",
            "Iteration 205, loss = 0.49134888\n",
            "Iteration 206, loss = 0.49123791\n",
            "Iteration 207, loss = 0.49015646\n",
            "Iteration 208, loss = 0.48966918\n",
            "Iteration 209, loss = 0.48997217\n",
            "Iteration 210, loss = 0.49110204\n",
            "Iteration 211, loss = 0.49168353\n",
            "Iteration 212, loss = 0.49105640\n",
            "Iteration 213, loss = 0.48962759\n",
            "Iteration 214, loss = 0.48851697\n",
            "Iteration 215, loss = 0.48829709\n",
            "Iteration 216, loss = 0.49056040\n",
            "Iteration 217, loss = 0.49029128\n",
            "Iteration 218, loss = 0.48910094\n",
            "Iteration 219, loss = 0.48730953\n",
            "Iteration 220, loss = 0.48693918\n",
            "Iteration 221, loss = 0.48646741\n",
            "Iteration 222, loss = 0.48652191\n",
            "Iteration 223, loss = 0.48721646\n",
            "Iteration 224, loss = 0.48820032\n",
            "Iteration 225, loss = 0.49018786\n",
            "Iteration 226, loss = 0.49078618\n",
            "Iteration 227, loss = 0.48846370\n",
            "Iteration 228, loss = 0.48499947\n",
            "Iteration 229, loss = 0.48316267\n",
            "Iteration 230, loss = 0.48343165\n",
            "Iteration 231, loss = 0.48600063\n",
            "Iteration 232, loss = 0.48818691\n",
            "Iteration 233, loss = 0.48679907\n",
            "Iteration 234, loss = 0.48405830\n",
            "Iteration 235, loss = 0.48154083\n",
            "Iteration 236, loss = 0.48098046\n",
            "Iteration 237, loss = 0.48039869\n",
            "Iteration 238, loss = 0.48034681\n",
            "Iteration 239, loss = 0.47994382\n",
            "Iteration 240, loss = 0.47982377\n",
            "Iteration 241, loss = 0.47906519\n",
            "Iteration 242, loss = 0.47898416\n",
            "Iteration 243, loss = 0.47921584\n",
            "Iteration 244, loss = 0.47903355\n",
            "Iteration 245, loss = 0.47869554\n",
            "Iteration 246, loss = 0.47854661\n",
            "Iteration 247, loss = 0.47826667\n",
            "Iteration 248, loss = 0.47787689\n",
            "Iteration 249, loss = 0.47761987\n",
            "Iteration 250, loss = 0.47728754\n",
            "Iteration 251, loss = 0.47645052\n",
            "Iteration 252, loss = 0.47604793\n",
            "Iteration 253, loss = 0.47548139\n",
            "Iteration 254, loss = 0.47514941\n",
            "Iteration 255, loss = 0.47475530\n",
            "Iteration 256, loss = 0.47483974\n",
            "Iteration 257, loss = 0.47486144\n",
            "Iteration 258, loss = 0.47426875\n",
            "Iteration 259, loss = 0.47337191\n",
            "Iteration 260, loss = 0.47324750\n",
            "Iteration 261, loss = 0.47411349\n",
            "Iteration 262, loss = 0.47466240\n",
            "Iteration 263, loss = 0.47460586\n",
            "Iteration 264, loss = 0.47348643\n",
            "Iteration 265, loss = 0.47148691\n",
            "Iteration 266, loss = 0.47097089\n",
            "Iteration 267, loss = 0.47399842\n",
            "Iteration 268, loss = 0.47593938\n",
            "Iteration 269, loss = 0.47530278\n",
            "Iteration 270, loss = 0.47285346\n",
            "Iteration 271, loss = 0.47060399\n",
            "Iteration 272, loss = 0.46956148\n",
            "Iteration 273, loss = 0.46988262\n",
            "Iteration 274, loss = 0.46928085\n",
            "Iteration 275, loss = 0.46918471\n",
            "Iteration 276, loss = 0.46833441\n",
            "Iteration 277, loss = 0.46800187\n",
            "Iteration 278, loss = 0.46765407\n",
            "Iteration 279, loss = 0.46740157\n",
            "Iteration 280, loss = 0.46722451\n",
            "Iteration 281, loss = 0.46675344\n",
            "Iteration 282, loss = 0.46587697\n",
            "Iteration 283, loss = 0.46562288\n",
            "Iteration 284, loss = 0.46654127\n",
            "Iteration 285, loss = 0.46695609\n",
            "Iteration 286, loss = 0.46653984\n",
            "Iteration 287, loss = 0.46558993\n",
            "Iteration 288, loss = 0.46507482\n",
            "Iteration 289, loss = 0.46433865\n",
            "Iteration 290, loss = 0.46409775\n",
            "Iteration 291, loss = 0.46376590\n",
            "Iteration 292, loss = 0.46345962\n",
            "Iteration 293, loss = 0.46307168\n",
            "Iteration 294, loss = 0.46265238\n",
            "Iteration 295, loss = 0.46254686\n",
            "Iteration 296, loss = 0.46199532\n",
            "Iteration 297, loss = 0.46196500\n",
            "Iteration 298, loss = 0.46153339\n",
            "Iteration 299, loss = 0.46120247\n",
            "Iteration 300, loss = 0.46145570\n",
            "Iteration 301, loss = 0.46230575\n",
            "Iteration 302, loss = 0.46312941\n",
            "Iteration 303, loss = 0.46283941\n",
            "Iteration 304, loss = 0.46233194\n",
            "Iteration 305, loss = 0.46112929\n",
            "Iteration 306, loss = 0.46064654\n",
            "Iteration 307, loss = 0.45980674\n",
            "Iteration 308, loss = 0.45871938\n",
            "Iteration 309, loss = 0.45781794\n",
            "Iteration 310, loss = 0.45723457\n",
            "Iteration 311, loss = 0.45769694\n",
            "Iteration 312, loss = 0.45774770\n",
            "Iteration 313, loss = 0.45717828\n",
            "Iteration 314, loss = 0.45622952\n",
            "Iteration 315, loss = 0.45553903\n",
            "Iteration 316, loss = 0.45509290\n",
            "Iteration 317, loss = 0.45467921\n",
            "Iteration 318, loss = 0.45538205\n",
            "Iteration 319, loss = 0.45573586\n",
            "Iteration 320, loss = 0.45534488\n",
            "Iteration 321, loss = 0.45434535\n",
            "Iteration 322, loss = 0.45403144\n",
            "Iteration 323, loss = 0.45325059\n",
            "Iteration 324, loss = 0.45309540\n",
            "Iteration 325, loss = 0.45310174\n",
            "Iteration 326, loss = 0.45277389\n",
            "Iteration 327, loss = 0.45224408\n",
            "Iteration 328, loss = 0.45256831\n",
            "Iteration 329, loss = 0.45318810\n",
            "Iteration 330, loss = 0.45377131\n",
            "Iteration 331, loss = 0.45314989\n",
            "Iteration 332, loss = 0.45124736\n",
            "Iteration 333, loss = 0.45028115\n",
            "Iteration 334, loss = 0.44992849\n",
            "Iteration 335, loss = 0.44935941\n",
            "Iteration 336, loss = 0.44978847\n",
            "Iteration 337, loss = 0.44949427\n",
            "Iteration 338, loss = 0.44966989\n",
            "Iteration 339, loss = 0.44967205\n",
            "Iteration 340, loss = 0.45080772\n",
            "Iteration 341, loss = 0.45116945\n",
            "Iteration 342, loss = 0.45052267\n",
            "Iteration 343, loss = 0.44912089\n",
            "Iteration 344, loss = 0.44811701\n",
            "Iteration 345, loss = 0.44776251\n",
            "Iteration 346, loss = 0.44664453\n",
            "Iteration 347, loss = 0.44602067\n",
            "Iteration 348, loss = 0.44591206\n",
            "Iteration 349, loss = 0.44566201\n",
            "Iteration 350, loss = 0.44534365\n",
            "Iteration 351, loss = 0.44522821\n",
            "Iteration 352, loss = 0.44532975\n",
            "Iteration 353, loss = 0.44568090\n",
            "Iteration 354, loss = 0.44524910\n",
            "Iteration 355, loss = 0.44425185\n",
            "Iteration 356, loss = 0.44333404\n",
            "Iteration 357, loss = 0.44263325\n",
            "Iteration 358, loss = 0.44211835\n",
            "Iteration 359, loss = 0.44272106\n",
            "Iteration 360, loss = 0.44230245\n",
            "Iteration 361, loss = 0.44076925\n",
            "Iteration 362, loss = 0.44150955\n",
            "Iteration 363, loss = 0.44288884\n",
            "Iteration 364, loss = 0.44458284\n",
            "Iteration 365, loss = 0.44446873\n",
            "Iteration 366, loss = 0.44210136\n",
            "Iteration 367, loss = 0.43951159\n",
            "Iteration 368, loss = 0.43869101\n",
            "Iteration 369, loss = 0.43973035\n",
            "Iteration 370, loss = 0.44130826\n",
            "Iteration 371, loss = 0.44031382\n",
            "Iteration 372, loss = 0.43846687\n",
            "Iteration 373, loss = 0.43761105\n",
            "Iteration 374, loss = 0.43740511\n",
            "Iteration 375, loss = 0.43745817\n",
            "Iteration 376, loss = 0.43737838\n",
            "Iteration 377, loss = 0.43674332\n",
            "Iteration 378, loss = 0.43633795\n",
            "Iteration 379, loss = 0.43644891\n",
            "Iteration 380, loss = 0.43720244\n",
            "Iteration 381, loss = 0.43826961\n",
            "Iteration 382, loss = 0.43813758\n",
            "Iteration 383, loss = 0.43708644\n",
            "Iteration 384, loss = 0.43613064\n",
            "Iteration 385, loss = 0.43505357\n",
            "Iteration 386, loss = 0.43433417\n",
            "Iteration 387, loss = 0.43416013\n",
            "Iteration 388, loss = 0.43358048\n",
            "Iteration 389, loss = 0.43330925\n",
            "Iteration 390, loss = 0.43285157\n",
            "Iteration 391, loss = 0.43247123\n",
            "Iteration 392, loss = 0.43208541\n",
            "Iteration 393, loss = 0.43177840\n",
            "Iteration 394, loss = 0.43116123\n",
            "Iteration 395, loss = 0.43042287\n",
            "Iteration 396, loss = 0.43008963\n",
            "Iteration 397, loss = 0.43022021\n",
            "Iteration 398, loss = 0.43431671\n",
            "Iteration 399, loss = 0.43573191\n",
            "Iteration 400, loss = 0.43435073\n",
            "Iteration 401, loss = 0.43186822\n",
            "Iteration 402, loss = 0.42967763\n",
            "Iteration 403, loss = 0.42922864\n",
            "Iteration 404, loss = 0.42828205\n",
            "Iteration 405, loss = 0.42785632\n",
            "Iteration 406, loss = 0.42755339\n",
            "Iteration 407, loss = 0.42745080\n",
            "Iteration 408, loss = 0.42735107\n",
            "Iteration 409, loss = 0.42751336\n",
            "Iteration 410, loss = 0.42666744\n",
            "Iteration 411, loss = 0.42623676\n",
            "Iteration 412, loss = 0.42645835\n",
            "Iteration 413, loss = 0.42982695\n",
            "Iteration 414, loss = 0.43344834\n",
            "Iteration 415, loss = 0.43307659\n",
            "Iteration 416, loss = 0.42978266\n",
            "Iteration 417, loss = 0.42560239\n",
            "Iteration 418, loss = 0.42371765\n",
            "Iteration 419, loss = 0.42630872\n",
            "Iteration 420, loss = 0.43080970\n",
            "Iteration 421, loss = 0.43137011\n",
            "Iteration 422, loss = 0.42854700\n",
            "Iteration 423, loss = 0.42480717\n",
            "Iteration 424, loss = 0.42383997\n",
            "Iteration 425, loss = 0.42273753\n",
            "Iteration 426, loss = 0.42282360\n",
            "Iteration 427, loss = 0.42189479\n",
            "Iteration 428, loss = 0.42215501\n",
            "Iteration 429, loss = 0.42316570\n",
            "Iteration 430, loss = 0.42409468\n",
            "Iteration 431, loss = 0.42434304\n",
            "Iteration 432, loss = 0.42380165\n",
            "Iteration 433, loss = 0.42251896\n",
            "Iteration 434, loss = 0.42123559\n",
            "Iteration 435, loss = 0.42032874\n",
            "Iteration 436, loss = 0.41939012\n",
            "Iteration 437, loss = 0.41844115\n",
            "Iteration 438, loss = 0.41950198\n",
            "Iteration 439, loss = 0.41911718\n",
            "Iteration 440, loss = 0.41782104\n",
            "Iteration 441, loss = 0.41794348\n",
            "Iteration 442, loss = 0.41882819\n",
            "Iteration 443, loss = 0.41928094\n",
            "Iteration 444, loss = 0.41846811\n",
            "Iteration 445, loss = 0.41715834\n",
            "Iteration 446, loss = 0.41672377\n",
            "Iteration 447, loss = 0.41653766\n",
            "Iteration 448, loss = 0.41683406\n",
            "Iteration 449, loss = 0.41626305\n",
            "Iteration 450, loss = 0.41539921\n",
            "Iteration 451, loss = 0.41568780\n",
            "Iteration 452, loss = 0.41534009\n",
            "Iteration 453, loss = 0.41492823\n",
            "Iteration 454, loss = 0.41422663\n",
            "Iteration 455, loss = 0.41410538\n",
            "Iteration 456, loss = 0.41393279\n",
            "Iteration 457, loss = 0.41401370\n",
            "Iteration 458, loss = 0.41380003\n",
            "Iteration 459, loss = 0.41337196\n",
            "Iteration 460, loss = 0.41291351\n",
            "Iteration 461, loss = 0.41240146\n",
            "Iteration 462, loss = 0.41222225\n",
            "Iteration 463, loss = 0.41197991\n",
            "Iteration 464, loss = 0.41123113\n",
            "Iteration 465, loss = 0.41262453\n",
            "Iteration 466, loss = 0.41673629\n",
            "Iteration 467, loss = 0.41734308\n",
            "Iteration 468, loss = 0.41434048\n",
            "Iteration 469, loss = 0.41130678\n",
            "Iteration 470, loss = 0.40986470\n",
            "Iteration 471, loss = 0.41044067\n",
            "Iteration 472, loss = 0.41245318\n",
            "Iteration 473, loss = 0.41512164\n",
            "Iteration 474, loss = 0.41460579\n",
            "Iteration 475, loss = 0.41149786\n",
            "Iteration 476, loss = 0.40948080\n",
            "Iteration 477, loss = 0.40915571\n",
            "Iteration 478, loss = 0.41050804\n",
            "Iteration 479, loss = 0.41085261\n",
            "Iteration 480, loss = 0.40918890\n",
            "Iteration 481, loss = 0.40815906\n",
            "Iteration 482, loss = 0.40744238\n",
            "Iteration 483, loss = 0.40752706\n",
            "Iteration 484, loss = 0.40664227\n",
            "Iteration 485, loss = 0.40683657\n",
            "Iteration 486, loss = 0.40587980\n",
            "Iteration 487, loss = 0.40605994\n",
            "Iteration 488, loss = 0.40724293\n",
            "Iteration 489, loss = 0.40922711\n",
            "Iteration 490, loss = 0.40907394\n",
            "Iteration 491, loss = 0.40698237\n",
            "Iteration 492, loss = 0.40594086\n",
            "Iteration 493, loss = 0.40600296\n",
            "Iteration 494, loss = 0.40534452\n",
            "Iteration 495, loss = 0.40428217\n",
            "Iteration 496, loss = 0.40299509\n",
            "Iteration 497, loss = 0.40362584\n",
            "Iteration 498, loss = 0.40446967\n",
            "Iteration 499, loss = 0.40480001\n",
            "Iteration 500, loss = 0.40350517\n",
            "Iteration 501, loss = 0.40239442\n",
            "Iteration 502, loss = 0.40240901\n",
            "Iteration 503, loss = 0.40244906\n",
            "Iteration 504, loss = 0.40245210\n",
            "Iteration 505, loss = 0.40185536\n",
            "Iteration 506, loss = 0.40064688\n",
            "Iteration 507, loss = 0.40044263\n",
            "Iteration 508, loss = 0.39993472\n",
            "Iteration 509, loss = 0.39953073\n",
            "Iteration 510, loss = 0.39985745\n",
            "Iteration 511, loss = 0.40007357\n",
            "Iteration 512, loss = 0.40001919\n",
            "Iteration 513, loss = 0.39940297\n",
            "Iteration 514, loss = 0.39878161\n",
            "Iteration 515, loss = 0.39846491\n",
            "Iteration 516, loss = 0.39888865\n",
            "Iteration 517, loss = 0.39920992\n",
            "Iteration 518, loss = 0.39870921\n",
            "Iteration 519, loss = 0.39813663\n",
            "Iteration 520, loss = 0.39731451\n",
            "Iteration 521, loss = 0.39665639\n",
            "Iteration 522, loss = 0.39655150\n",
            "Iteration 523, loss = 0.39648375\n",
            "Iteration 524, loss = 0.39596917\n",
            "Iteration 525, loss = 0.39533582\n",
            "Iteration 526, loss = 0.39443574\n",
            "Iteration 527, loss = 0.39427682\n",
            "Iteration 528, loss = 0.39405038\n",
            "Iteration 529, loss = 0.39393965\n",
            "Iteration 530, loss = 0.39454709\n",
            "Iteration 531, loss = 0.39382299\n",
            "Iteration 532, loss = 0.39478504\n",
            "Iteration 533, loss = 0.39537424\n",
            "Iteration 534, loss = 0.39527693\n",
            "Iteration 535, loss = 0.39493151\n",
            "Iteration 536, loss = 0.39443395\n",
            "Iteration 537, loss = 0.39318751\n",
            "Iteration 538, loss = 0.39274246\n",
            "Iteration 539, loss = 0.39255106\n",
            "Iteration 540, loss = 0.39218782\n",
            "Iteration 541, loss = 0.39169137\n",
            "Iteration 542, loss = 0.39180346\n",
            "Iteration 543, loss = 0.39105351\n",
            "Iteration 544, loss = 0.39027943\n",
            "Iteration 545, loss = 0.39104027\n",
            "Iteration 546, loss = 0.39411146\n",
            "Iteration 547, loss = 0.39438225\n",
            "Iteration 548, loss = 0.39064870\n",
            "Iteration 549, loss = 0.38846199\n",
            "Iteration 550, loss = 0.39179501\n",
            "Iteration 551, loss = 0.39425801\n",
            "Iteration 552, loss = 0.39300145\n",
            "Iteration 553, loss = 0.38971009\n",
            "Iteration 554, loss = 0.38917107\n",
            "Iteration 555, loss = 0.38856384\n",
            "Iteration 556, loss = 0.38914698\n",
            "Iteration 557, loss = 0.39193636\n",
            "Iteration 558, loss = 0.39174436\n",
            "Iteration 559, loss = 0.38935751\n",
            "Iteration 560, loss = 0.38685161\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/raul/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (560) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-10 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-10 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-10 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-10 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-10 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-10 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-10 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-10 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-10 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-10 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-10 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-10 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-10 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-10 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-10 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-10 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-10 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"â–¸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-10 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-10 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-10 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-10 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"â–¾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-10 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-10 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-10 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-10 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-10 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-10 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-10 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-10 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-10 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-10 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-10 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-10 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-10 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-10 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-10 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(max_iter=560, verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MLPClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.neural_network.MLPClassifier.html\">?<span>Documentation for MLPClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MLPClassifier(max_iter=560, verbose=True)</pre></div> </div></div></div></div>"
            ],
            "text/plain": [
              "MLPClassifier(max_iter=560, verbose=True)"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "modelo = MLPClassifier(max_iter=560, verbose=True)\n",
        "modelo.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6Q1RssrJU9z",
        "outputId": "802b6904-3a64-4a71-fd3b-221c672f3524"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.69999672\n",
            "Iteration 2, loss = 0.68019737\n",
            "Iteration 3, loss = 0.66528800\n",
            "Iteration 4, loss = 0.65364176\n",
            "Iteration 5, loss = 0.64681829\n",
            "Iteration 6, loss = 0.63726586\n",
            "Iteration 7, loss = 0.62837896\n",
            "Iteration 8, loss = 0.62126696\n",
            "Iteration 9, loss = 0.61426504\n",
            "Iteration 10, loss = 0.60888112\n",
            "Iteration 11, loss = 0.60380675\n",
            "Iteration 12, loss = 0.59914501\n",
            "Iteration 13, loss = 0.59410850\n",
            "Iteration 14, loss = 0.58966990\n",
            "Iteration 15, loss = 0.58664268\n",
            "Iteration 16, loss = 0.58279635\n",
            "Iteration 17, loss = 0.58005106\n",
            "Iteration 18, loss = 0.57765185\n",
            "Iteration 19, loss = 0.57533160\n",
            "Iteration 20, loss = 0.57307819\n",
            "Iteration 21, loss = 0.57111502\n",
            "Iteration 22, loss = 0.57077535\n",
            "Iteration 23, loss = 0.57007095\n",
            "Iteration 24, loss = 0.56890034\n",
            "Iteration 25, loss = 0.56694415\n",
            "Iteration 26, loss = 0.56530832\n",
            "Iteration 27, loss = 0.56350645\n",
            "Iteration 28, loss = 0.56195283\n",
            "Iteration 29, loss = 0.56092632\n",
            "Iteration 30, loss = 0.55911724\n",
            "Iteration 31, loss = 0.55662013\n",
            "Iteration 32, loss = 0.55530331\n",
            "Iteration 33, loss = 0.55784555\n",
            "Iteration 34, loss = 0.56080481\n",
            "Iteration 35, loss = 0.56058084\n",
            "Iteration 36, loss = 0.55825090\n",
            "Iteration 37, loss = 0.55587001\n",
            "Iteration 38, loss = 0.55365746\n",
            "Iteration 39, loss = 0.55111111\n",
            "Iteration 40, loss = 0.54972269\n",
            "Iteration 41, loss = 0.54886150\n",
            "Iteration 42, loss = 0.54857991\n",
            "Iteration 43, loss = 0.54896681\n",
            "Iteration 44, loss = 0.54979754\n",
            "Iteration 45, loss = 0.54977018\n",
            "Iteration 46, loss = 0.54925018\n",
            "Iteration 47, loss = 0.54806846\n",
            "Iteration 48, loss = 0.54673809\n",
            "Iteration 49, loss = 0.54463123\n",
            "Iteration 50, loss = 0.54366394\n",
            "Iteration 51, loss = 0.54368361\n",
            "Iteration 52, loss = 0.54500815\n",
            "Iteration 53, loss = 0.54407488\n",
            "Iteration 54, loss = 0.54270494\n",
            "Iteration 55, loss = 0.54177484\n",
            "Iteration 56, loss = 0.54116265\n",
            "Iteration 57, loss = 0.54072600\n",
            "Iteration 58, loss = 0.54002841\n",
            "Iteration 59, loss = 0.53903133\n",
            "Iteration 60, loss = 0.53787239\n",
            "Iteration 61, loss = 0.53726599\n",
            "Iteration 62, loss = 0.53744788\n",
            "Iteration 63, loss = 0.53716464\n",
            "Iteration 64, loss = 0.53674262\n",
            "Iteration 65, loss = 0.53663239\n",
            "Iteration 66, loss = 0.53947292\n",
            "Iteration 67, loss = 0.53968699\n",
            "Iteration 68, loss = 0.53802098\n",
            "Iteration 69, loss = 0.53641407\n",
            "Iteration 70, loss = 0.53408933\n",
            "Iteration 71, loss = 0.53263950\n",
            "Iteration 72, loss = 0.53169522\n",
            "Iteration 73, loss = 0.53138843\n",
            "Iteration 74, loss = 0.53082573\n",
            "Iteration 75, loss = 0.53021513\n",
            "Iteration 76, loss = 0.52953674\n",
            "Iteration 77, loss = 0.52905553\n",
            "Iteration 78, loss = 0.52923058\n",
            "Iteration 79, loss = 0.52860368\n",
            "Iteration 80, loss = 0.52779046\n",
            "Iteration 81, loss = 0.52721203\n",
            "Iteration 82, loss = 0.52667686\n",
            "Iteration 83, loss = 0.52669255\n",
            "Iteration 84, loss = 0.52724214\n",
            "Iteration 85, loss = 0.52688879\n",
            "Iteration 86, loss = 0.52577691\n",
            "Iteration 87, loss = 0.52414612\n",
            "Iteration 88, loss = 0.52323669\n",
            "Iteration 89, loss = 0.52292277\n",
            "Iteration 90, loss = 0.52334796\n",
            "Iteration 91, loss = 0.52439425\n",
            "Iteration 92, loss = 0.52404682\n",
            "Iteration 93, loss = 0.52214853\n",
            "Iteration 94, loss = 0.52028433\n",
            "Iteration 95, loss = 0.51899958\n",
            "Iteration 96, loss = 0.51974949\n",
            "Iteration 97, loss = 0.51965104\n",
            "Iteration 98, loss = 0.51828152\n",
            "Iteration 99, loss = 0.51730908\n",
            "Iteration 100, loss = 0.51750370\n",
            "Iteration 101, loss = 0.51835495\n",
            "Iteration 102, loss = 0.51911384\n",
            "Iteration 103, loss = 0.51897772\n",
            "Iteration 104, loss = 0.51793272\n",
            "Iteration 105, loss = 0.51656689\n",
            "Iteration 106, loss = 0.51552106\n",
            "Iteration 107, loss = 0.51435827\n",
            "Iteration 108, loss = 0.51408730\n",
            "Iteration 109, loss = 0.51324485\n",
            "Iteration 110, loss = 0.51299206\n",
            "Iteration 111, loss = 0.51234186\n",
            "Iteration 112, loss = 0.51190449\n",
            "Iteration 113, loss = 0.51151583\n",
            "Iteration 114, loss = 0.51098542\n",
            "Iteration 115, loss = 0.51058548\n",
            "Iteration 116, loss = 0.51025423\n",
            "Iteration 117, loss = 0.50994189\n",
            "Iteration 118, loss = 0.50925049\n",
            "Iteration 119, loss = 0.50963061\n",
            "Iteration 120, loss = 0.50937523\n",
            "Iteration 121, loss = 0.50787662\n",
            "Iteration 122, loss = 0.50782808\n",
            "Iteration 123, loss = 0.50861104\n",
            "Iteration 124, loss = 0.50847066\n",
            "Iteration 125, loss = 0.50670670\n",
            "Iteration 126, loss = 0.50478503\n",
            "Iteration 127, loss = 0.50826326\n",
            "Iteration 128, loss = 0.51106078\n",
            "Iteration 129, loss = 0.51368247\n",
            "Iteration 130, loss = 0.51443301\n",
            "Iteration 131, loss = 0.51202465\n",
            "Iteration 132, loss = 0.50754102\n",
            "Iteration 133, loss = 0.50529872\n",
            "Iteration 134, loss = 0.50353379\n",
            "Iteration 135, loss = 0.50298849\n",
            "Iteration 136, loss = 0.50252066\n",
            "Iteration 137, loss = 0.50230948\n",
            "Iteration 138, loss = 0.50201949\n",
            "Iteration 139, loss = 0.50136305\n",
            "Iteration 140, loss = 0.50373508\n",
            "Iteration 141, loss = 0.50540892\n",
            "Iteration 142, loss = 0.50570254\n",
            "Iteration 143, loss = 0.50362920\n",
            "Iteration 144, loss = 0.50106632\n",
            "Iteration 145, loss = 0.49993260\n",
            "Iteration 146, loss = 0.49899943\n",
            "Iteration 147, loss = 0.49871092\n",
            "Iteration 148, loss = 0.49803872\n",
            "Iteration 149, loss = 0.49754600\n",
            "Iteration 150, loss = 0.49707652\n",
            "Iteration 151, loss = 0.49717553\n",
            "Iteration 152, loss = 0.49737041\n",
            "Iteration 153, loss = 0.49755726\n",
            "Iteration 154, loss = 0.49791603\n",
            "Iteration 155, loss = 0.49695985\n",
            "Iteration 156, loss = 0.49566081\n",
            "Iteration 157, loss = 0.49455898\n",
            "Iteration 158, loss = 0.49413727\n",
            "Iteration 159, loss = 0.49410701\n",
            "Iteration 160, loss = 0.49434966\n",
            "Iteration 161, loss = 0.49393654\n",
            "Iteration 162, loss = 0.49314911\n",
            "Iteration 163, loss = 0.49262302\n",
            "Iteration 164, loss = 0.49211976\n",
            "Iteration 165, loss = 0.49159279\n",
            "Iteration 166, loss = 0.49116102\n",
            "Iteration 167, loss = 0.49093302\n",
            "Iteration 168, loss = 0.49076257\n",
            "Iteration 169, loss = 0.49091607\n",
            "Iteration 170, loss = 0.49095109\n",
            "Iteration 171, loss = 0.49026954\n",
            "Iteration 172, loss = 0.48956743\n",
            "Iteration 173, loss = 0.48849050\n",
            "Iteration 174, loss = 0.48834562\n",
            "Iteration 175, loss = 0.48835482\n",
            "Iteration 176, loss = 0.48797348\n",
            "Iteration 177, loss = 0.48770814\n",
            "Iteration 178, loss = 0.48794334\n",
            "Iteration 179, loss = 0.48852655\n",
            "Iteration 180, loss = 0.48768854\n",
            "Iteration 181, loss = 0.48646490\n",
            "Iteration 182, loss = 0.48605698\n",
            "Iteration 183, loss = 0.48539976\n",
            "Iteration 184, loss = 0.48478897\n",
            "Iteration 185, loss = 0.48444433\n",
            "Iteration 186, loss = 0.48393315\n",
            "Iteration 187, loss = 0.48418137\n",
            "Iteration 188, loss = 0.48529483\n",
            "Iteration 189, loss = 0.48615734\n",
            "Iteration 190, loss = 0.48788609\n",
            "Iteration 191, loss = 0.48718302\n",
            "Iteration 192, loss = 0.48363462\n",
            "Iteration 193, loss = 0.48259386\n",
            "Iteration 194, loss = 0.48436988\n",
            "Iteration 195, loss = 0.48566717\n",
            "Iteration 196, loss = 0.48599419\n",
            "Iteration 197, loss = 0.48479787\n",
            "Iteration 198, loss = 0.48200629\n",
            "Iteration 199, loss = 0.48156599\n",
            "Iteration 200, loss = 0.48040568\n",
            "Iteration 201, loss = 0.48101409\n",
            "Iteration 202, loss = 0.48045774\n",
            "Iteration 203, loss = 0.47947848\n",
            "Iteration 204, loss = 0.47879025\n",
            "Iteration 205, loss = 0.47783506\n",
            "Iteration 206, loss = 0.47735772\n",
            "Iteration 207, loss = 0.47762763\n",
            "Iteration 208, loss = 0.47776548\n",
            "Iteration 209, loss = 0.47730554\n",
            "Iteration 210, loss = 0.47618148\n",
            "Iteration 211, loss = 0.47600626\n",
            "Iteration 212, loss = 0.47643124\n",
            "Iteration 213, loss = 0.47671964\n",
            "Iteration 214, loss = 0.47754807\n",
            "Iteration 215, loss = 0.47667415\n",
            "Iteration 216, loss = 0.47504365\n",
            "Iteration 217, loss = 0.47417760\n",
            "Iteration 218, loss = 0.47341817\n",
            "Iteration 219, loss = 0.47292767\n",
            "Iteration 220, loss = 0.47222485\n",
            "Iteration 221, loss = 0.47198588\n",
            "Iteration 222, loss = 0.47311541\n",
            "Iteration 223, loss = 0.47383849\n",
            "Iteration 224, loss = 0.47445713\n",
            "Iteration 225, loss = 0.47343906\n",
            "Iteration 226, loss = 0.47217552\n",
            "Iteration 227, loss = 0.47044708\n",
            "Iteration 228, loss = 0.47003408\n",
            "Iteration 229, loss = 0.46959922\n",
            "Iteration 230, loss = 0.46980581\n",
            "Iteration 231, loss = 0.47105343\n",
            "Iteration 232, loss = 0.47098456\n",
            "Iteration 233, loss = 0.47011322\n",
            "Iteration 234, loss = 0.46966913\n",
            "Iteration 235, loss = 0.46850887\n",
            "Iteration 236, loss = 0.46734063\n",
            "Iteration 237, loss = 0.46693517\n",
            "Iteration 238, loss = 0.46745874\n",
            "Iteration 239, loss = 0.46832605\n",
            "Iteration 240, loss = 0.46794485\n",
            "Iteration 241, loss = 0.46599971\n",
            "Iteration 242, loss = 0.46533367\n",
            "Iteration 243, loss = 0.46518844\n",
            "Iteration 244, loss = 0.46460307\n",
            "Iteration 245, loss = 0.46443716\n",
            "Iteration 246, loss = 0.46378528\n",
            "Iteration 247, loss = 0.46352338\n",
            "Iteration 248, loss = 0.46335430\n",
            "Iteration 249, loss = 0.46383237\n",
            "Iteration 250, loss = 0.46453872\n",
            "Iteration 251, loss = 0.46485257\n",
            "Iteration 252, loss = 0.46435474\n",
            "Iteration 253, loss = 0.46253663\n",
            "Iteration 254, loss = 0.46145038\n",
            "Iteration 255, loss = 0.46100128\n",
            "Iteration 256, loss = 0.46286786\n",
            "Iteration 257, loss = 0.46400873\n",
            "Iteration 258, loss = 0.46368860\n",
            "Iteration 259, loss = 0.46215911\n",
            "Iteration 260, loss = 0.46007525\n",
            "Iteration 261, loss = 0.45930725\n",
            "Iteration 262, loss = 0.45841966\n",
            "Iteration 263, loss = 0.45795351\n",
            "Iteration 264, loss = 0.45810421\n",
            "Iteration 265, loss = 0.45843289\n",
            "Iteration 266, loss = 0.45779229\n",
            "Iteration 267, loss = 0.45714444\n",
            "Iteration 268, loss = 0.45629922\n",
            "Iteration 269, loss = 0.45637650\n",
            "Iteration 270, loss = 0.45691418\n",
            "Iteration 271, loss = 0.45595385\n",
            "Iteration 272, loss = 0.45537674\n",
            "Iteration 273, loss = 0.45618188\n",
            "Iteration 274, loss = 0.45613806\n",
            "Iteration 275, loss = 0.45542529\n",
            "Iteration 276, loss = 0.45436160\n",
            "Iteration 277, loss = 0.45373703\n",
            "Iteration 278, loss = 0.45286500\n",
            "Iteration 279, loss = 0.45384009\n",
            "Iteration 280, loss = 0.45366295\n",
            "Iteration 281, loss = 0.45270557\n",
            "Iteration 282, loss = 0.45184382\n",
            "Iteration 283, loss = 0.45160448\n",
            "Iteration 284, loss = 0.45148368\n",
            "Iteration 285, loss = 0.45107020\n",
            "Iteration 286, loss = 0.45049537\n",
            "Iteration 287, loss = 0.45033940\n",
            "Iteration 288, loss = 0.45094122\n",
            "Iteration 289, loss = 0.45111277\n",
            "Iteration 290, loss = 0.45029489\n",
            "Iteration 291, loss = 0.44874518\n",
            "Iteration 292, loss = 0.44862238\n",
            "Iteration 293, loss = 0.44867987\n",
            "Iteration 294, loss = 0.44840211\n",
            "Iteration 295, loss = 0.44771047\n",
            "Iteration 296, loss = 0.44897722\n",
            "Iteration 297, loss = 0.45432194\n",
            "Iteration 298, loss = 0.45698604\n",
            "Iteration 299, loss = 0.45524964\n",
            "Iteration 300, loss = 0.45082964\n",
            "Iteration 301, loss = 0.44607046\n",
            "Iteration 302, loss = 0.44730292\n",
            "Iteration 303, loss = 0.45319477\n",
            "Iteration 304, loss = 0.45455295\n",
            "Iteration 305, loss = 0.45137522\n",
            "Iteration 306, loss = 0.44670947\n",
            "Iteration 307, loss = 0.44471603\n",
            "Iteration 308, loss = 0.44626806\n",
            "Iteration 309, loss = 0.44682825\n",
            "Iteration 310, loss = 0.44542033\n",
            "Iteration 311, loss = 0.44400964\n",
            "Iteration 312, loss = 0.44433325\n",
            "Iteration 313, loss = 0.44454458\n",
            "Iteration 314, loss = 0.44422147\n",
            "Iteration 315, loss = 0.44351849\n",
            "Iteration 316, loss = 0.44251824\n",
            "Iteration 317, loss = 0.44233590\n",
            "Iteration 318, loss = 0.44179516\n",
            "Iteration 319, loss = 0.44140941\n",
            "Iteration 320, loss = 0.44097604\n",
            "Iteration 321, loss = 0.44079132\n",
            "Iteration 322, loss = 0.44016276\n",
            "Iteration 323, loss = 0.44001936\n",
            "Iteration 324, loss = 0.43927427\n",
            "Iteration 325, loss = 0.43911828\n",
            "Iteration 326, loss = 0.43957596\n",
            "Iteration 327, loss = 0.44054814\n",
            "Iteration 328, loss = 0.44161060\n",
            "Iteration 329, loss = 0.44068955\n",
            "Iteration 330, loss = 0.43933448\n",
            "Iteration 331, loss = 0.43849829\n",
            "Iteration 332, loss = 0.43786457\n",
            "Iteration 333, loss = 0.43724343\n",
            "Iteration 334, loss = 0.43694937\n",
            "Iteration 335, loss = 0.43642348\n",
            "Iteration 336, loss = 0.43596517\n",
            "Iteration 337, loss = 0.43561864\n",
            "Iteration 338, loss = 0.43759102\n",
            "Iteration 339, loss = 0.43462356\n",
            "Iteration 340, loss = 0.43503635\n",
            "Iteration 341, loss = 0.44069465\n",
            "Iteration 342, loss = 0.43927509\n",
            "Iteration 343, loss = 0.43462031\n",
            "Iteration 344, loss = 0.43492523\n",
            "Iteration 345, loss = 0.43971806\n",
            "Iteration 346, loss = 0.44166377\n",
            "Iteration 347, loss = 0.43964986\n",
            "Iteration 348, loss = 0.43662787\n",
            "Iteration 349, loss = 0.43371123\n",
            "Iteration 350, loss = 0.43305778\n",
            "Iteration 351, loss = 0.43204831\n",
            "Iteration 352, loss = 0.43207198\n",
            "Iteration 353, loss = 0.43169791\n",
            "Iteration 354, loss = 0.43111563\n",
            "Iteration 355, loss = 0.43085657\n",
            "Iteration 356, loss = 0.43025236\n",
            "Iteration 357, loss = 0.42962311\n",
            "Iteration 358, loss = 0.43161322\n",
            "Iteration 359, loss = 0.43092371\n",
            "Iteration 360, loss = 0.42925129\n",
            "Iteration 361, loss = 0.42926718\n",
            "Iteration 362, loss = 0.43295284\n",
            "Iteration 363, loss = 0.43533482\n",
            "Iteration 364, loss = 0.43469290\n",
            "Iteration 365, loss = 0.43252898\n",
            "Iteration 366, loss = 0.42955391\n",
            "Iteration 367, loss = 0.42867603\n",
            "Iteration 368, loss = 0.42912005\n",
            "Iteration 369, loss = 0.43048259\n",
            "Iteration 370, loss = 0.43051331\n",
            "Iteration 371, loss = 0.42816097\n",
            "Iteration 372, loss = 0.42923989\n",
            "Iteration 373, loss = 0.43053066\n",
            "Iteration 374, loss = 0.43132553\n",
            "Iteration 375, loss = 0.43021595\n",
            "Iteration 376, loss = 0.42851354\n",
            "Iteration 377, loss = 0.42733487\n",
            "Iteration 378, loss = 0.42599805\n",
            "Iteration 379, loss = 0.42573673\n",
            "Iteration 380, loss = 0.42482012\n",
            "Iteration 381, loss = 0.42412071\n",
            "Iteration 382, loss = 0.42443176\n",
            "Iteration 383, loss = 0.42442538\n",
            "Iteration 384, loss = 0.42409514\n",
            "Iteration 385, loss = 0.42408515\n",
            "Iteration 386, loss = 0.42431595\n",
            "Iteration 387, loss = 0.42397003\n",
            "Iteration 388, loss = 0.42300118\n",
            "Iteration 389, loss = 0.42392338\n",
            "Iteration 390, loss = 0.42308843\n",
            "Iteration 391, loss = 0.42185344\n",
            "Iteration 392, loss = 0.42195833\n",
            "Iteration 393, loss = 0.42319071\n",
            "Iteration 394, loss = 0.42330500\n",
            "Iteration 395, loss = 0.42157880\n",
            "Iteration 396, loss = 0.42105738\n",
            "Iteration 397, loss = 0.42100259\n",
            "Iteration 398, loss = 0.42231257\n",
            "Iteration 399, loss = 0.42571459\n",
            "Iteration 400, loss = 0.42948731\n",
            "Iteration 401, loss = 0.43082939\n",
            "Iteration 402, loss = 0.42731497\n",
            "Iteration 403, loss = 0.42387063\n",
            "Iteration 404, loss = 0.42325140\n",
            "Iteration 405, loss = 0.42377585\n",
            "Iteration 406, loss = 0.42301460\n",
            "Iteration 407, loss = 0.42043125\n",
            "Iteration 408, loss = 0.41887359\n",
            "Iteration 409, loss = 0.41839913\n",
            "Iteration 410, loss = 0.41871606\n",
            "Iteration 411, loss = 0.41879236\n",
            "Iteration 412, loss = 0.41912841\n",
            "Iteration 413, loss = 0.41880605\n",
            "Iteration 414, loss = 0.41785131\n",
            "Iteration 415, loss = 0.41746721\n",
            "Iteration 416, loss = 0.41686065\n",
            "Iteration 417, loss = 0.41617370\n",
            "Iteration 418, loss = 0.41558784\n",
            "Iteration 419, loss = 0.41509987\n",
            "Iteration 420, loss = 0.41450061\n",
            "Iteration 421, loss = 0.41440741\n",
            "Iteration 422, loss = 0.41442948\n",
            "Iteration 423, loss = 0.41426565\n",
            "Iteration 424, loss = 0.41385963\n",
            "Iteration 425, loss = 0.41353779\n",
            "Iteration 426, loss = 0.41382576\n",
            "Iteration 427, loss = 0.41356924\n",
            "Iteration 428, loss = 0.41345184\n",
            "Iteration 429, loss = 0.41263980\n",
            "Iteration 430, loss = 0.41286307\n",
            "Iteration 431, loss = 0.41270767\n",
            "Iteration 432, loss = 0.41270073\n",
            "Iteration 433, loss = 0.41239533\n",
            "Iteration 434, loss = 0.41190645\n",
            "Iteration 435, loss = 0.41221761\n",
            "Iteration 436, loss = 0.41167457\n",
            "Iteration 437, loss = 0.41061158\n",
            "Iteration 438, loss = 0.41030546\n",
            "Iteration 439, loss = 0.41271387\n",
            "Iteration 440, loss = 0.41413000\n",
            "Iteration 441, loss = 0.41207024\n",
            "Iteration 442, loss = 0.40944461\n",
            "Iteration 443, loss = 0.40922184\n",
            "Iteration 444, loss = 0.41100082\n",
            "Iteration 445, loss = 0.41088651\n",
            "Iteration 446, loss = 0.40946004\n",
            "Iteration 447, loss = 0.40864138\n",
            "Iteration 448, loss = 0.40876360\n",
            "Iteration 449, loss = 0.40921330\n",
            "Iteration 450, loss = 0.40810399\n",
            "Iteration 451, loss = 0.40776656\n",
            "Iteration 452, loss = 0.40836404\n",
            "Iteration 453, loss = 0.40866429\n",
            "Iteration 454, loss = 0.40854501\n",
            "Iteration 455, loss = 0.40815989\n",
            "Iteration 456, loss = 0.40693062\n",
            "Iteration 457, loss = 0.40642721\n",
            "Iteration 458, loss = 0.40659232\n",
            "Iteration 459, loss = 0.40589694\n",
            "Iteration 460, loss = 0.40578975\n",
            "Iteration 461, loss = 0.40750746\n",
            "Iteration 462, loss = 0.40889821\n",
            "Iteration 463, loss = 0.40866794\n",
            "Iteration 464, loss = 0.40729513\n",
            "Iteration 465, loss = 0.40684187\n",
            "Iteration 466, loss = 0.40625067\n",
            "Iteration 467, loss = 0.40594347\n",
            "Iteration 468, loss = 0.40531077\n",
            "Iteration 469, loss = 0.40427272\n",
            "Iteration 470, loss = 0.40385399\n",
            "Iteration 471, loss = 0.40306357\n",
            "Iteration 472, loss = 0.40345270\n",
            "Iteration 473, loss = 0.40312980\n",
            "Iteration 474, loss = 0.40261774\n",
            "Iteration 475, loss = 0.40252361\n",
            "Iteration 476, loss = 0.40220039\n",
            "Iteration 477, loss = 0.40172831\n",
            "Iteration 478, loss = 0.40110163\n",
            "Iteration 479, loss = 0.40048491\n",
            "Iteration 480, loss = 0.40071675\n",
            "Iteration 481, loss = 0.40121542\n",
            "Iteration 482, loss = 0.40181897\n",
            "Iteration 483, loss = 0.40191405\n",
            "Iteration 484, loss = 0.40155603\n",
            "Iteration 485, loss = 0.40090924\n",
            "Iteration 486, loss = 0.40036815\n",
            "Iteration 487, loss = 0.40010005\n",
            "Iteration 488, loss = 0.39980065\n",
            "Iteration 489, loss = 0.39958867\n",
            "Iteration 490, loss = 0.39870787\n",
            "Iteration 491, loss = 0.39957901\n",
            "Iteration 492, loss = 0.40122582\n",
            "Iteration 493, loss = 0.40146717\n",
            "Iteration 494, loss = 0.39992210\n",
            "Iteration 495, loss = 0.39838005\n",
            "Iteration 496, loss = 0.39770970\n",
            "Iteration 497, loss = 0.39706369\n",
            "Iteration 498, loss = 0.39707552\n",
            "Iteration 499, loss = 0.39807628\n",
            "Iteration 500, loss = 0.39948934\n",
            "Iteration 501, loss = 0.40017597\n",
            "Iteration 502, loss = 0.39946419\n",
            "Iteration 503, loss = 0.39684172\n",
            "Iteration 504, loss = 0.39675374\n",
            "Iteration 505, loss = 0.39659059\n",
            "Iteration 506, loss = 0.39649551\n",
            "Iteration 507, loss = 0.39674604\n",
            "Iteration 508, loss = 0.39613924\n",
            "Iteration 509, loss = 0.39549531\n",
            "Iteration 510, loss = 0.39472497\n",
            "Iteration 511, loss = 0.39439302\n",
            "Iteration 512, loss = 0.39399584\n",
            "Iteration 513, loss = 0.39470298\n",
            "Iteration 514, loss = 0.39354778\n",
            "Iteration 515, loss = 0.39251175\n",
            "Iteration 516, loss = 0.39319676\n",
            "Iteration 517, loss = 0.39461184\n",
            "Iteration 518, loss = 0.39432809\n",
            "Iteration 519, loss = 0.39304742\n",
            "Iteration 520, loss = 0.39356963\n",
            "Iteration 521, loss = 0.39352197\n",
            "Iteration 522, loss = 0.39294515\n",
            "Iteration 523, loss = 0.39272916\n",
            "Iteration 524, loss = 0.39241511\n",
            "Iteration 525, loss = 0.39305760\n",
            "Iteration 526, loss = 0.39365797\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-13 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-13 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-13 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-13 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-13 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-13 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-13 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-13 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-13 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-13 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-13 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-13 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-13 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-13 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-13 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-13 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-13 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"â–¸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-13 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-13 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-13 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-13 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"â–¾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-13 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-13 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-13 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-13 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-13 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-13 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-13 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-13 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-13 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-13 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-13 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-13 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-13 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-13 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-13 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(max_iter=560, verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MLPClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.neural_network.MLPClassifier.html\">?<span>Documentation for MLPClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MLPClassifier(max_iter=560, verbose=True)</pre></div> </div></div></div></div>"
            ],
            "text/plain": [
              "MLPClassifier(max_iter=560, verbose=True)"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rede_neural = MLPClassifier(max_iter=560, verbose=True, tol=0.00000000000001, solver = 'adam', activation = 'relu', hidden_layer_sizes = 9)\n",
        "modelo.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "1q9nsbSjdu23"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
              "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1])"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "previsoes = modelo.predict(x_test)\n",
        "previsoes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJ9MxYOIfmwv",
        "outputId": "d81573e1-45aa-4ea6-d922-c25e1a623343"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7068965517241379"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "accuracy_score(y_test,previsoes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3D5bvushr9W",
        "outputId": "45328eb3-d2be-4d4c-c5e1-248e262d7d9e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[34,  6],\n",
              "       [11,  7]])"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from yellowbrick.classifier import ConfusionMatrix\n",
        "confusion_matrix(y_test, previsoes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "wX15YT-7j-c9",
        "outputId": "db8b53f9-e72b-4257-c955-a229ab056d41"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/raul/.local/lib/python3.10/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.7068965517241379"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x550 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "cm = ConfusionMatrix(modelo)\n",
        "cm.fit(x_train, y_train)\n",
        "cm.score(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIixOPw1kw-z",
        "outputId": "5b4735c0-0e3f-4981-b422-f4a5d25f5c76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.85      0.80        40\n",
            "           1       0.54      0.39      0.45        18\n",
            "\n",
            "    accuracy                           0.71        58\n",
            "   macro avg       0.65      0.62      0.63        58\n",
            "weighted avg       0.69      0.71      0.69        58\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, previsoes))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csRtFY7lKr0N"
      },
      "source": [
        "**Veja como implementar o backpropagation em python:**\n",
        "https://www.askpython.com/python/examples/backpropagation-in-python\n",
        "https://www.deeplearningbook.com.br/algoritmo-backpropagation-em-python/\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
